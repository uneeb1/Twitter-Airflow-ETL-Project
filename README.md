# Twitter-Airflow-ETL-Project

Overview
This project demonstrates an end-to-end data engineering solution that extracts real-time data from the Twitter API, transforms it using Python, and stores the results on Amazon S3. By leveraging Apache Airflow for workflow automation, this project efficiently processes data and provides actionable insights.

Technologies Used
Python: For data extraction and transformation
Apache Airflow: For orchestrating ETL workflows
Amazon EC2: For hosting Airflow and executing workflows
Amazon S3: For scalable and durable data storage
Twitter API: For extracting real-time tweets
Features
Real-Time Data Extraction: Automatically fetches data from Twitter to provide timely insights.
Automated ETL Workflows: Uses Apache Airflow to streamline data processing, minimizing manual intervention.
Scalable Storage: Stores processed data in Amazon S3, ensuring durability and easy access for future analysis.
Getting Started
Prerequisites
Python 3.x
Apache Airflow
AWS account (for EC2 and S3)
Twitter Developer Account (for API access)
